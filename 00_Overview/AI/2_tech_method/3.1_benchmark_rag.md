# Benchmark RAG

Khi bạn triển khai hệ thống RAG, không phải cứ “tìm được rồi đưa vào LLM” là đảm bảo trả lời đúng. Vẫn có thể gặp lỗi như:

- **Trả lời sai (hallucination)** dù đã retrieve đúng
- **Tìm nhầm đoạn liên quan** (`semantic` search kém)
- **Câu trả lời lặp, lan man hoặc thiếu sót**

link tham kháo: https://www.pinecone.io/learn/offline-evaluation/

━━━━━━━━━━━━━━━━━━ ∘◦ ✧ ✦ ✧ ◦∘ ━━━━━━━━━━━━━━━━━━

## ✅ WHAT – Benchmark RAG là gì?

Là quá trình **đánh giá hiệu quả toàn bộ pipeline RAG**:

Từ tìm kiếm → đến sinh câu trả lời → đến độ chính xác cuối cùng.

> **📌 Mục tiêu: Giảm lỗi, tăng độ tin cậy, tăng độ chính xác**

━━━━━━━━━━━━━━━━━━ ∘◦ ✧ ✦ ✧ ◦∘ ━━━━━━━━━━━━━━━━━━

## ✅ WHY – Tại sao cần benchmark RAG?

RAG là **tổ hợp 2 mô-đun AI tách biệt:**

- 📥 Retrieval (tìm dữ liệu)
- 🧠 Generation (sinh câu trả lời)

Nếu không đo lường rõ:

- **Bạn không biết lỗi xảy ra ở đâu** (retrieval hay LLM)
- **Bạn không biết cần cải thiện phần nào** (embedding? chunking? prompt?)

━━━━━━━━━━━━━━━━━━ ∘◦ ✧ ✦ ✧ ◦∘ ━━━━━━━━━━━━━━━━━━

## ✅ HOW – Benchmark RAG: Đo cái gì?

### ✳️ Có 3 cấp độ đo lường:

### 1. 📥 Đo Retrieval – Đo xem tìm đoạn có đúng không?

| Metric                   | Ý nghĩa                                                |
| ------------------------ | ------------------------------------------------------ |
| **Recall\@k**            | Trong top-k kết quả retrieve, có chứa đoạn đúng không? |
| **Precision\@k**         | Trong top-k, bao nhiêu đoạn thực sự liên quan?         |
| **Embedding similarity** | Vector câu hỏi gần vector chunk đúng không?            |

✅ → Nếu retrieve sai → cần cải thiện chunking, embedding, vector search

---

### 2. 🧠 Đo Generation – LLM có dùng đúng dữ liệu để trả lời không?

| Metric                             | Ý nghĩa                                         |
| ---------------------------------- | ----------------------------------------------- |
| **Faithfulness (tính trung thực)** | Trả lời có bám sát dữ liệu được retrieve không? |
| **Factuality (tính chính xác)**    | Có nói sai sự thật không?                       |
| **Tính đầy đủ**                    | Trả lời có đủ thông tin không, hay thiếu?       |

✅ → Nếu LLM bịa → cần điều chỉnh prompt, giảm độ "tưởng tượng"

---

### 3. 🧪 Đo tổng thể – Câu trả lời có tốt không?

| Metric                     | Ý nghĩa                                          |
| -------------------------- | ------------------------------------------------ |
| **EM (Exact Match)**       | Câu trả lời có trùng hoàn toàn với ground truth? |
| **ROUGE, BLEU, BERTScore** | So sánh độ giống ngữ nghĩa với đáp án chuẩn      |
| **Human Eval**             | Con người chấm điểm: đúng, rõ, đầy đủ, tự tin    |

✅ → Đây là đánh giá chất lượng thực tế

━━━━━━━━━━━━━━━━━━ ∘◦ ✧ ✦ ✧ ◦∘ ━━━━━━━━━━━━━━━━━━

## ✅ Một lỗi rất phổ biến trong RAG:

> Tìm đúng đoạn – nhưng GPT không dùng, vẫn bịa

### Lý do:

- Prompt không nhấn mạnh: "Chỉ được trả lời từ context"
- GPT thích “sáng tạo”, đặc biệt với prompt mở
- LLM không biết đánh giá độ tin cậy của đoạn retrieved

### 🛠 Cách xử lý:

- Dùng prompt dạng:

  > "Dưới đây là thông tin tài liệu. **Trả lời chỉ dựa vào thông tin dưới**, nếu không đủ thì trả lời **'Tôi không chắc'**."

- Hoặc dùng mô hình kiểm tra faithfulness sau khi sinh ra câu trả lời

━━━━━━━━━━━━━━━━━━ ∘◦ ✧ ✦ ✧ ◦∘ ━━━━━━━━━━━━━━━━━━

## ✅ Kết hợp: Retrieval QA Evaluation Pipelines

Một flow benchmark đơn giản:

```bash
1. Input: Câu hỏi + Ground Truth Answer
2. Embedding → Semantic Search → Top-K đoạn
3. Check: có chứa đoạn đúng không? (Recall@k)
4. Prompt LLM sinh câu trả lời
5. Check: câu trả lời có đúng không? (EM, BLEU, Faithfulness)
```

Bạn có thể dùng:

- **LangChain Benchmarks**
- **Ragas (from RAGEval)**
- **Custom pipeline + human review**

━━━━━━━━━━━━━━━━━━ ∘◦ ✧ ✦ ✧ ◦∘ ━━━━━━━━━━━━━━━━━━

## ✅ Tóm tắt 80/20:

| Cấp đo        | Đo gì?                     | Tối ưu gì?                     |
| ------------- | -------------------------- | ------------------------------ |
| 📥 Retrieval  | Tìm đúng đoạn không?       | Embedding, chunking, vector DB |
| 🧠 Generation | Dùng đúng thông tin không? | Prompt, LLM behavior           |
| ✅ Tổng thể   | Câu trả lời có đúng không? | Cả 2 phần trên                 |
