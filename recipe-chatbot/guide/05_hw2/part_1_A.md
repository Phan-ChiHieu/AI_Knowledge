# Vi·∫øt function t·ª± ƒë√¥ng t·∫°o ra c√¢u h·ªèi theo y√™u c·∫ßu c·ªßa Question

- ƒê∆∞·ª£c vi·∫øt to√†n b·ªô trong m·ªôt file: homeworks/hw2/generate_synthetic_queries.py

## I. Import th∆∞ vi·ªán

```python
import json, os
from pathlib import Path
from typing import List, Optional, Dict, Any
from pydantic import BaseModel
import pandas as pd
from litellm import completion
from dotenv import load_dotenv
from concurrent.futures import ThreadPoolExecutor, as_completed
import time
from tqdm import tqdm


#  Load bi·∫øn m√¥i tr∆∞·ªùng
load_dotenv()
# ‚Üí Load bi·∫øn OPENAI_API_KEY t·ª´ file .env.
```

| Th∆∞ vi·ªán                             | T√°c d·ª•ng                                     |
| ------------------------------------ | -------------------------------------------- |
| `json`, `os`, `pathlib`              | ƒê·ªçc/ghi file, thao t√°c path, bi·∫øn m√¥i tr∆∞·ªùng |
| `typing`, `pydantic`                 | X√°c ƒë·ªãnh ki·ªÉu d·ªØ li·ªáu v√† validate            |
| `pandas`                             | X·ª≠ l√Ω d·ªØ li·ªáu b·∫£ng v√† xu·∫•t CSV               |
| `litellm`                            | G·ªçi LLM model (·ªü ƒë√¢y l√† GPT-4o-mini)         |
| `dotenv`                             | Load bi·∫øn m√¥i tr∆∞·ªùng t·ª´ `.env`               |
| `ThreadPoolExecutor`, `as_completed` | G·ªçi LLM song song (multi-thread)             |
| `tqdm`                               | Hi·ªÉn th·ªã progress bar khi ch·∫°y               |

---

---

## II. ƒê·ªãnh nghƒ©a schema d·ªØ li·ªáu b·∫±ng Pydantic

```python
# --- Pydantic Models for Structured Output ---
class DimensionTuple(BaseModel):
    DietaryNeedsOrRestrictions: str
    AvailableIngredientsFocus: str
    CuisinePreference: str
    SkillLevelEffort: str
    TimeAvailability: str
    QueryStyleAndDetail: str
```

| Dimension                    | √ù nghƒ©a                                                          |
| ---------------------------- | ---------------------------------------------------------------- |
| `DietaryNeedsOrRestrictions` | Nhu c·∫ßu ƒÉn u·ªëng (ƒÉn chay, kh√¥ng gluten, v.v.)                    |
| `AvailableIngredientsFocus`  | Ng∆∞·ªùi d√πng c√≥ s·∫µn nguy√™n li·ªáu n√†o                                |
| `CuisinePreference`          | H·ªç th√≠ch m√≥n g√¨ (Th√°i, √ù, v.v.) ho·∫∑c tr√°nh m√≥n g√¨                |
| `SkillLevelEffort`           | Tr√¨nh ƒë·ªô n·∫•u ƒÉn (d·ªÖ, trung b√¨nh, kh√≥)                            |
| `TimeAvailability`           | C√≥ bao nhi√™u th·ªùi gian (d∆∞ d·∫£ hay g·∫•p)                           |
| `QueryStyleAndDetail`        | C√°ch h·ªç ƒë·∫∑t c√¢u h·ªèi (ng·∫Øn g·ªçn hay chi ti·∫øt, c√≥ typo, emoji v.v.) |

‚Üí M·ªói "dimension tuple" m√¥ t·∫£ m·ªôt ng∆∞·ªùi d√πng.

```python
class QueryWithDimensions(BaseModel):
    id: str
    query: str
    dimension_tuple: DimensionTuple
    is_realistic_and_kept: int = 1
    notes_for_filtering: str = ""
```

‚Üí M·ªói truy v·∫•n s·∫Ω ƒëi k√®m v·ªõi dimension_tuple.

```python
class DimensionTuplesList(BaseModel):
    tuples: List[DimensionTuple]

class QueriesList(BaseModel):
    queries: List[str]
```

‚Üí C√°c class n√†y d√πng ƒë·ªÉ parse k·∫øt qu·∫£ JSON tr·∫£ v·ªÅ t·ª´ GPT.

---

---

## III. Config

```python
# --- Configuration ---
MODEL_NAME = "gpt-4o-mini"
NUM_TUPLES_TO_GENERATE = 10
NUM_QUERIES_PER_TUPLE = 5
OUTPUT_CSV_PATH = Path(__file__).parent / "synthetic_queries_for_analysis.csv"
MAX_WORKERS = 5
```

‚Üí S·ªë l∆∞·ª£ng tuple c·∫ßn sinh ra, s·ªë query m·ªói tuple, s·ªë lu·ªìng x·ª≠ l√Ω song song.

---

---

## IV. G·ªçi GPT ƒë·ªÉ sinh ra d·ªØ li·ªáu

```python
def call_llm(messages: List[Dict[str, str]], response_format: Any) -> Any:
    """Make a single LLM call with retries."""
    max_retries = 3
    for attempt in range(max_retries):
        try:
            response = completion(
                model=MODEL_NAME,
                messages=messages,
                response_format=response_format
            )
            return response_format(**json.loads(response.choices[0].message.content))
        except Exception as e:
            if attempt == max_retries - 1:
                raise e
            time.sleep(1)  # Wait before retry
```

ƒê√¢y l√† **gi·∫£i th√≠ch chi ti·∫øt t·ª´ng d√≤ng** cho h√†m `call_llm`, m·ªôt h√†m quan tr·ªçng d√πng ƒë·ªÉ **g·ªçi GPT (qua `litellm.completion`) v√† parse k·∫øt qu·∫£ v·ªÅ m·ªôt schema c·ª• th·ªÉ** (d·ª±a v√†o `pydantic`).

### ‚ú≥Ô∏è M·ª•c ƒë√≠ch:

H√†m n√†y g·ª≠i `messages` (ki·ªÉu ChatGPT) ƒë·∫øn GPT model v√† **parse ph·∫£n h·ªìi th√†nh m·ªôt object theo `response_format`**.

## üì¶ H√†m ƒë·∫ßy ƒë·ªß:

```python
def call_llm(messages: List[Dict[str, str]], response_format: Any) -> Any:
    """Make a single LLM call with retries."""
    max_retries = 3
```

- Nh·∫≠n 2 tham s·ªë:

  - `messages`: danh s√°ch message ki·ªÉu ChatML, v√≠ d·ª•:

    ```python
    [
      {"role": "system", "content": "..."},
      {"role": "user", "content": "..."}
    ]
    ```

  - `response_format`: m·ªôt l·ªõp `pydantic` ƒë·ªÉ ƒë·ªãnh nghƒ©a ki·ªÉu d·ªØ li·ªáu ƒë·∫ßu ra. VD: `DimensionTuplesList`, `QueriesList`...

- G·ªçi l·∫°i GPT **t·ªëi ƒëa 3 l·∫ßn** n·∫øu g·∫∑p l·ªói.

### üîÅ V√≤ng l·∫∑p v·ªõi retry:

```python
    for attempt in range(max_retries):
```

L·∫∑p t·ªëi ƒëa 3 l·∫ßn trong tr∆∞·ªùng h·ª£p GPT b·ªã timeout/l·ªói m·∫°ng.

### üéØ G·ªçi GPT:

```python
        try:
            response = completion(
                model=MODEL_NAME,
                messages=messages,
                response_format=response_format
            )
```

- G·ªçi h√†m `completion()` t·ª´ th∆∞ vi·ªán `litellm`, g·ª≠i `messages` v√† `model` (VD: `"gpt-4o-mini"`).
- `response_format` ·ªü ƒë√¢y l√† th√¥ng tin m√¥ t·∫£ ki·ªÉu d·ªØ li·ªáu GPT s·∫Ω tr·∫£ v·ªÅ (d∆∞·ªõi d·∫°ng JSON string).

### üì¶ Parse k·∫øt qu·∫£:

```python
            return response_format(**json.loads(response.choices[0].message.content))
```

- `response.choices[0].message.content`: n·ªôi dung text tr·∫£ v·ªÅ t·ª´ GPT (chu·ªói JSON).
- `json.loads(...)`: chuy·ªÉn t·ª´ JSON string th√†nh Python `dict`
- `response_format(**...)`: d√πng `pydantic` ƒë·ªÉ t·∫°o object ƒë√∫ng chu·∫©n schema ƒë·∫ßu v√†o, v√≠ d·ª•:

  ```python
  response_format = DimensionTuplesList
  ‚áí return DimensionTuplesList(**<dict t·ª´ json>)
  ```

### ‚ùå N·∫øu l·ªói: retry

```python
        except Exception as e:
            if attempt == max_retries - 1:
                raise e
            time.sleep(1)  # Wait before retry
```

- N·∫øu l·ªói (v√≠ d·ª• l·ªói m·∫°ng, l·ªói JSON parse...), h√†m s·∫Ω:

  - **th·ª≠ l·∫°i** n·∫øu ch∆∞a ƒë·ªß 3 l·∫ßn
  - N·∫øu ƒë√£ h·∫øt l·∫ßn th·ª≠, **n√©m l·ªói l√™n** (`raise e`)
  - Ch·ªù 1 gi√¢y tr∆∞·ªõc khi th·ª≠ l·∫°i (`time.sleep(1)`)

## ‚úÖ V√≠ d·ª• th·ª±c t·∫ø:

```python
response_format = DimensionTuplesList
messages = [
  {"role": "system", "content": "You are a helpful assistant..."},
  {"role": "user", "content": "Generate 10 dimension tuples..."}
]

result = call_llm(messages, DimensionTuplesList)
print(result.tuples[0].CuisinePreference)  # truy c·∫≠p d·ªØ li·ªáu nh∆∞ object
```

## üß† T·ªïng k·∫øt:

| Th√†nh ph·∫ßn                           | Gi·∫£i th√≠ch                                                                   |
| ------------------------------------ | ---------------------------------------------------------------------------- |
| `completion(...)`                    | G·ª≠i prompt ƒë·∫øn GPT model                                                     |
| `response_format(**json.loads(...))` | Parse k·∫øt qu·∫£ GPT th√†nh object Pydantic                                      |
| `retry`                              | Gi√∫p ch·ªëng l·ªói m·∫°ng ho·∫∑c GPT fail t·∫°m th·ªùi                                   |
| `response_format`                    | T√πy bi·∫øn ƒë·ªÉ t√°i s·ª≠ d·ª•ng: c√≥ th·ªÉ l√† `DimensionTuplesList`, `QueriesList`, v.v |

---

---

## V. G·ªçi GPT ƒë·ªÉ sinh ra d·ªØ li·ªáu

```python
def generate_dimension_tuples() -> List[DimensionTuple]:
    """Generate diverse dimension tuples."""
    prompt = f"""Generate {NUM_TUPLES_TO_GENERATE} diverse combinations of dimension values for a recipe chatbot.
Each combination should represent a different user scenario. Ensure balanced coverage across all dimensions - don't over-represent any particular value or combination.

Important: Aim for an even distribution across all dimensions. For example:
- Don't generate too many dietary restrictions combinations
- Don't focus too heavily on quick recipes
- Don't over-represent any particular cuisine
- Vary the query styles naturally
- Try to use weird combinations of ingredients required in AvailableIngredientsFocus

DietaryNeedsOrRestrictions:
- vegan, vegetarian, gluten-free, dairy-free, keto, paleo, halal, kosher, no restrictions, pescatarian, low-carb, low-sodium, nut-free, egg-free, soy-free, FODMAP, diabetic-friendly, high-protein

AvailableIngredientsFocus:
- must_use_specific: [list of ingredients]
- general_pantry: basic ingredients
- no_specific_ingredients: open to suggestions

CuisinePreference:
- specific_cuisine: [cuisine type]
- any_cuisine
- avoid_specific: [cuisine type]

SkillLevelEffort:
- beginner_easy_low_effort
- intermediate_moderate_effort
- advanced_complex_high_effort

TimeAvailability:
- quick_under_30_mins
- moderate_30_to_60_mins
- flexible_no_time_constraint

QueryStyleAndDetail:
- short_keywords_minimal_detail
- natural_question_moderate_detail
- detailed_request_high_detail

Here are some example dimension tuples that show realistic combinations:

1. Beginner cook with time constraints and specific ingredients:
{{
    "DietaryNeedsOrRestrictions": "no restrictions",
    "AvailableIngredientsFocus": "must_use_specific: chicken breast, rice, vegetables",
    "CuisinePreference": "any_cuisine",
    "SkillLevelEffort": "beginner_easy_low_effort",
    "TimeAvailability": "quick_under_30_mins",
    "QueryStyleAndDetail": "natural_question_moderate_detail"
}}

2. Experienced cook with dietary restrictions and flexible time:
{{
    "DietaryNeedsOrRestrictions": "vegan",
    "AvailableIngredientsFocus": "general_pantry",
    "CuisinePreference": "specific_cuisine: mediterranean",
    "SkillLevelEffort": "advanced_complex_high_effort",
    "TimeAvailability": "flexible_no_time_constraint",
    "QueryStyleAndDetail": "detailed_request_high_detail"
}}

3. Busy parent with dietary needs and pantry ingredients:
{{
    "DietaryNeedsOrRestrictions": "gluten_free",
    "AvailableIngredientsFocus": "general_pantry",
    "CuisinePreference": "avoid_specific: spicy",
    "SkillLevelEffort": "intermediate_moderate_effort",
    "TimeAvailability": "moderate_30_to_60_mins",
    "QueryStyleAndDetail": "short_keywords_minimal_detail"
}}

4. Student with limited ingredients and quick time:
{{
    "DietaryNeedsOrRestrictions": "vegetarian",
    "AvailableIngredientsFocus": "must_use_specific: pasta, canned tomatoes, cheese",
    "CuisinePreference": "any_cuisine",
    "SkillLevelEffort": "beginner_easy_low_effort",
    "TimeAvailability": "quick_under_30_mins",
    "QueryStyleAndDetail": "natural_question_moderate_detail"
}}

5. Food enthusiast with specific cuisine preference:
{{
    "DietaryNeedsOrRestrictions": "no restrictions",
    "AvailableIngredientsFocus": "no_specific_ingredients",
    "CuisinePreference": "specific_cuisine: thai",
    "SkillLevelEffort": "intermediate_moderate_effort",
    "TimeAvailability": "moderate_30_to_60_mins",
    "QueryStyleAndDetail": "detailed_request_high_detail"
}}

Generate {NUM_TUPLES_TO_GENERATE} unique dimension tuples following these patterns. Remember to maintain balanced diversity across all dimensions."""

    messages = [{"role": "user", "content": prompt}]

    try:
        print("Generating dimension tuples in parallel...")
        with ThreadPoolExecutor(max_workers=5) as executor:
            # Submit five generation tasks using a loop
            futures = []
            for _ in range(5):
                futures.append(executor.submit(call_llm, messages, DimensionTuplesList))

            # Wait for all to complete and collect results
            responses = []
            for future in futures:
                responses.append(future.result())

        # Combine tuples and remove duplicates
        all_tuples = []
        for response in responses:
            all_tuples.extend(response.tuples)
        unique_tuples = []
        seen = set()

        for tup in all_tuples:
            # Convert tuple to a comparable string representation
            tuple_str = tup.model_dump_json()
            if tuple_str not in seen:
                seen.add(tuple_str)
                unique_tuples.append(tup)

        print(f"Generated {len(all_tuples)} total tuples, {len(unique_tuples)} unique")
        return unique_tuples
    except Exception as e:
        print(f"Error generating dimension tuples: {e}")
        return []
```

H√†m `generate_dimension_tuples()` l√† m·ªôt **h√†m sinh d·ªØ li·ªáu ƒë·∫ßu v√†o ƒëa d·∫°ng cho chatbot n·∫•u ƒÉn**, s·ª≠ d·ª•ng GPT ƒë·ªÉ t·∫°o ra c√°c "dimension tuples" (t·ªï h·ª£p nhi·ªÅu bi·∫øn li√™n quan ƒë·∫øn nhu c·∫ßu ng∆∞·ªùi d√πng).

## ‚úÖ M·ª•c ƒë√≠ch

Sinh ra nhi·ªÅu t√¨nh hu·ªëng ng∆∞·ªùi d√πng kh√°c nhau, m·ªói t√¨nh hu·ªëng l√† m·ªôt "dimension tuple" g·ªìm c√°c thu·ªôc t√≠nh nh∆∞:

- `DietaryNeedsOrRestrictions` (h·∫°n ch·∫ø dinh d∆∞·ª°ng)
- `AvailableIngredientsFocus` (nguy√™n li·ªáu c√≥ s·∫µn)
- `CuisinePreference` (∆∞u ti√™n ·∫©m th·ª±c)
- `SkillLevelEffort` (tr√¨nh ƒë·ªô n·∫•u ƒÉn)
- `TimeAvailability` (th·ªùi gian r·∫£nh)
- `QueryStyleAndDetail` (c√°ch h·ªèi)

## üß† Gi·∫£i th√≠ch chi ti·∫øt

### 1. Prompt y√™u c·∫ßu GPT sinh d·ªØ li·ªáu:

```python
prompt = f"""Generate {NUM_TUPLES_TO_GENERATE} diverse combinations of dimension values ...
```

- GPT ƒë∆∞·ª£c h∆∞·ªõng d·∫´n:

  - Sinh ra c√°c t·ªï h·ª£p kh√°c nhau gi·ªØa c√°c dimension
  - Tr√°nh thi√™n l·ªách (v√≠ d·ª• sinh qu√° nhi·ªÅu m√≥n ‚Äúnhanh‚Äù, hay ‚Äúvegan‚Äù)
  - ƒê∆∞a v√≠ d·ª• c·ª• th·ªÉ ƒë·ªÉ h∆∞·ªõng GPT ƒëi ƒë√∫ng h∆∞·ªõng
  - C√°c value nh∆∞ `"must_use_specific: ..."`, `"specific_cuisine: ..."`, `"avoid_specific: ..."` ƒë·ªÅu l√† **label + gi√° tr·ªã** d·∫°ng key\:value

### 2. T·∫°o messages cho GPT:

```python
messages = [{"role": "user", "content": prompt}]
```

- ƒê∆∞a prompt v√†o ƒë·ªãnh d·∫°ng ChatGPT (ki·ªÉu list message).

### 3. G·ªçi GPT song song b·∫±ng ThreadPool:

```python
with ThreadPoolExecutor(max_workers=5) as executor:
    futures = []
    for _ in range(5):
        futures.append(executor.submit(call_llm, messages, DimensionTuplesList))
```

- G·ªçi GPT **5 l·∫ßn song song** ƒë·ªÉ tƒÉng kh·∫£ nƒÉng ƒëa d·∫°ng h√≥a k·∫øt qu·∫£.
- M·ªói l·∫ßn tr·∫£ v·ªÅ l√† m·ªôt `DimensionTuplesList` ‚Äì ch·ª©a nhi·ªÅu `DimensionTuple`.

### 4. Gom k·∫øt qu·∫£ v√† l·ªçc tr√πng:

```python
for response in responses:
    all_tuples.extend(response.tuples)

seen = set()
for tup in all_tuples:
    tuple_str = tup.model_dump_json()
    if tuple_str not in seen:
        seen.add(tuple_str)
        unique_tuples.append(tup)
```

- Gom t·∫•t c·∫£ c√°c tuple l·∫°i
- D√πng JSON string ƒë·ªÉ so s√°nh v√† l·ªçc tr√πng (v√¨ object kh√¥ng hashable tr·ª±c ti·∫øp)
- K·∫øt qu·∫£ l√† list `unique_tuples`

### 5. K·∫øt qu·∫£:

```python
print(f"Generated {len(all_tuples)} total tuples, {len(unique_tuples)} unique")
return unique_tuples
```

## üß© C√°c th√†nh ph·∫ßn ph·ª• thu·ªôc:

| T√™n                      | Gi·∫£i th√≠ch                                                                              |
| ------------------------ | --------------------------------------------------------------------------------------- |
| `call_llm()`             | H√†m ƒë√£ ph√¢n t√≠ch tr∆∞·ªõc: g·ªçi GPT v√† parse k·∫øt qu·∫£                                        |
| `DimensionTuplesList`    | M·ªôt l·ªõp `Pydantic`, ki·ªÉu `BaseModel`, g·ªìm field `tuples: List[DimensionTuple]`          |
| `DimensionTuple`         | M·ªôt c·∫•u tr√∫c ch·ª©a c√°c field nh∆∞ `DietaryNeedsOrRestrictions`, `CuisinePreference`, v.v. |
| `NUM_TUPLES_TO_GENERATE` | S·ªë l∆∞·ª£ng tuple mong mu·ªën GPT t·∫°o trong m·ªôt l·∫ßn g·ªçi                                      |

## üí° T√≥m l·∫°i

H√†m n√†y:

- **G·ªçi GPT nhi·ªÅu l·∫ßn song song** ƒë·ªÉ sinh d·ªØ li·ªáu ƒë·∫ßu v√†o m·∫´u cho bot
- **Tr√°nh tr√πng l·∫∑p**, ƒë·∫£m b·∫£o **ƒëa d·∫°ng v√† c√¢n b·∫±ng**
- **Tr·∫£ v·ªÅ danh s√°ch c√°c t√¨nh hu·ªëng ng∆∞·ªùi d√πng c·ª• th·ªÉ**, d√πng cho:

  - Ki·ªÉm th·ª≠ bot
  - Sinh c√¢u h·ªèi
  - Ph√¢n t√≠ch l·ªói

---

---

## VI. H√†m generate_queries_for_tuple() d√πng ƒë·ªÉ sinh c√°c c√¢u h·ªèi t·ª± nhi√™n m√† ng∆∞·ªùi d√πng c√≥ th·ªÉ h·ªèi chatbot d·ª±a tr√™n m·ªôt t·ªï h·ª£p ƒëi·ªÅu ki·ªán (dimension tuple).

```python
def generate_queries_for_tuple(dimension_tuple: DimensionTuple) -> List[str]:
    """Generate natural language queries for a given dimension tuple."""
    prompt = f"""Generate {NUM_QUERIES_PER_TUPLE} different natural language queries for a recipe chatbot based on these characteristics:
{dimension_tuple.model_dump_json(indent=2)}

The queries should:
1. Sound like real users asking for recipe help
2. Naturally incorporate all the dimension values
3. Vary in style and detail level
4. Be realistic and practical
5. Include natural variations in typing style, such as:
   - Some queries in all lowercase
   - Some with random capitalization
   - Some with common typos
   - Some with missing punctuation
   - Some with extra spaces or missing spaces
   - Some with emojis or text speak

Here are examples of realistic query variations for a beginner, vegan, quick recipe:

Proper formatting:
- "Need a simple vegan dinner that's ready in 20 minutes"
- "What's an easy plant-based recipe I can make quickly?"

All lowercase:
- "need a quick vegan recipe for dinner"
- "looking for easy plant based meals"

Random caps:
- "NEED a Quick Vegan DINNER recipe"
- "what's an EASY plant based recipe i can make"

Common typos:
- "need a quik vegan recip for dinner"
- "wat's an easy plant based recipe i can make"

Missing punctuation:
- "need vegan dinner ideas quick"
- "easy plant based recipe 20 mins"

With emojis/text speak:
- "need vegan dinner ideas asap! ü•ó"
- "pls help with quick plant based recipe thx"

Generate {NUM_QUERIES_PER_TUPLE} unique queries that match the given dimensions, varying the text style naturally."""

    messages = [{"role": "user", "content": prompt}]

    try:
        response = call_llm(messages, QueriesList)
        return response.queries
    except Exception as e:
        print(f"Error generating queries for tuple: {e}")
        return []

```

## üéØ M·ª•c ƒë√≠ch:

T·ª´ m·ªôt t·ªï h·ª£p c√°c ƒë·∫∑c ƒëi·ªÉm ng∆∞·ªùi d√πng (v√≠ d·ª•: ‚Äúvegan‚Äù, ‚Äúbeginner‚Äù, ‚Äúquick meal‚Äù), h√†m n√†y s·∫Ω:

- G·ªçi GPT ƒë·ªÉ sinh ra `NUM_QUERIES_PER_TUPLE` c√¢u h·ªèi **gi·ªëng ng∆∞·ªùi th·∫≠t h·ªèi**.
- C√°c c√¢u h·ªèi s·∫Ω ƒëa d·∫°ng v·ªÅ:

  - Ki·ªÉu vi·∫øt
  - M·ª©c ƒë·ªô chi ti·∫øt
  - Phong c√°ch g√µ (sai ch√≠nh t·∫£, vi·∫øt th∆∞·ªùng, c√≥ emoji‚Ä¶)

## üìå Ph√¢n t√≠ch t·ª´ng ph·∫ßn:

### 1. Nh·∫≠n ƒë·∫ßu v√†o:

```python
def generate_queries_for_tuple(dimension_tuple: DimensionTuple) -> List[str]:
```

- `dimension_tuple`: l√† m·ªôt t·ªï h·ª£p ƒë·∫∑c ƒëi·ªÉm ng∆∞·ªùi d√πng (v√≠ d·ª•: ƒÉn chay, √≠t th·ªùi gian, th√≠ch m√≥n √ù‚Ä¶)
- Ki·ªÉu d·ªØ li·ªáu: `DimensionTuple` ‚Äì m·ªôt `Pydantic model`

### 2. T·∫°o Prompt cho GPT:

```python
prompt = f"""Generate {NUM_QUERIES_PER_TUPLE} different natural language queries ..."""
```

#### üëâ N·ªôi dung prompt c√≥:

- **M√¥ t·∫£ m·ª•c ti√™u**: sinh c√°c c√¢u h·ªèi gi·ªëng ng∆∞·ªùi th·∫≠t s·∫Ω h·ªèi chatbot
- **D·ªØ li·ªáu ƒë·∫ßu v√†o**: `dimension_tuple` ƒë∆∞·ª£c dump ra JSON (d·ªÖ ƒë·ªçc)

  ```python
  {dimension_tuple.model_dump_json(indent=2)}
  ```

- **Y√™u c·∫ßu GPT** sinh query v·ªõi:

  - N·ªôi dung ph√π h·ª£p v·ªõi dimension tuple
  - Ki·ªÉu vi·∫øt ƒëa d·∫°ng:

    - Vi·∫øt th∆∞·ªùng
    - In hoa ng·∫´u nhi√™n
    - L·ªói ch√≠nh t·∫£
    - Kh√¥ng d·∫•u c√¢u
    - C√≥ emoji

- **V√≠ d·ª• c·ª• th·ªÉ** ƒë·ªÉ GPT h·ªçc c√°ch sinh phong ph√∫.

### 3. G·ªçi GPT ƒë·ªÉ sinh query:

```python
messages = [{"role": "user", "content": prompt}]
response = call_llm(messages, QueriesList)
```

- `call_llm`: h√†m g·ªçi GPT ƒë√£ gi·∫£i th√≠ch tr∆∞·ªõc
- `QueriesList`: class Pydantic ƒë·ªãnh nghƒ©a ki·ªÉu d·ªØ li·ªáu `queries: List[str]`

### 4. X·ª≠ l√Ω k·∫øt qu·∫£:

```python
return response.queries
```

- Tr·∫£ v·ªÅ list c√°c query GPT sinh ra (d∆∞·ªõi d·∫°ng chu·ªói)
- N·∫øu l·ªói, in l·ªói v√† tr·∫£ v·ªÅ list r·ªóng

```python
except Exception as e:
    print(f"Error generating queries for tuple: {e}")
    return []
```

## üß© C√°c ph·∫ßn ph·ª• thu·ªôc:

| T√™n                     | Vai tr√≤                                          |
| ----------------------- | ------------------------------------------------ |
| `DimensionTuple`        | Class ch·ª©a c√°c dimension: diet, cuisine, effort‚Ä¶ |
| `QueriesList`           | Pydantic model ch·ª©a field `queries: List[str]`   |
| `NUM_QUERIES_PER_TUPLE` | S·ªë l∆∞·ª£ng c√¢u h·ªèi c·∫ßn sinh ra                     |
| `call_llm`              | G·ªçi GPT v√† parse k·∫øt qu·∫£ v·ªÅ ki·ªÉu mong mu·ªën       |

## üí° T·ªïng k·∫øt:

H√†m n√†y l√† b∆∞·ªõc th·ª© hai sau `generate_dimension_tuples()`:

| B∆∞·ªõc                           | M·ª•c ƒë√≠ch                                                           |
| ------------------------------ | ------------------------------------------------------------------ |
| `generate_dimension_tuples()`  | Sinh ra c√°c t√¨nh hu·ªëng ng∆∞·ªùi d√πng ƒëa d·∫°ng                          |
| `generate_queries_for_tuple()` | Chuy·ªÉn t·ª´ng t√¨nh hu·ªëng th√†nh c√¢u h·ªèi c·ª• th·ªÉ nh∆∞ ng∆∞·ªùi d√πng h·ªèi bot |

---

---

## VII. H√†m generate_queries_parallel() d√πng ƒë·ªÉ generate h√†ng lo·∫°t c√¢u h·ªèi (queries) t·ª´ nhi·ªÅu t·ªï h·ª£p dimension_tuple, ch·∫°y song song (multi-threading) ƒë·ªÉ tƒÉng t·ªëc ƒë·ªô.

```python
def generate_queries_parallel(dimension_tuples: List[DimensionTuple]) -> List[QueryWithDimensions]:
    """Generate queries in parallel for all dimension tuples."""
    all_queries = []
    query_id = 1

    print(f"Generating {NUM_QUERIES_PER_TUPLE} queries each for {len(dimension_tuples)} dimension tuples...")

    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        # Submit all query generation tasks
        future_to_tuple = {
            executor.submit(generate_queries_for_tuple, dim_tuple): i
            for i, dim_tuple in enumerate(dimension_tuples)
        }

        # Process completed generations as they finish
        with tqdm(total=len(dimension_tuples), desc="Generating Queries") as pbar:
            for future in as_completed(future_to_tuple):
                tuple_idx = future_to_tuple[future]
                try:
                    queries = future.result()
                    if queries:
                        for query in queries:
                            all_queries.append(QueryWithDimensions(
                                id=f"SYN{query_id:03d}",
                                query=query,
                                dimension_tuple=dimension_tuples[tuple_idx]
                            ))
                            query_id += 1
                    pbar.update(1)
                except Exception as e:
                    print(f"Tuple {tuple_idx + 1} generated an exception: {e}")
                    pbar.update(1)

    return all_queries
```

## ‚úÖ M·ª•c ti√™u:

- Cho m·ªôt danh s√°ch `dimension_tuples` (t·ª©c l√† c√°c t·ªï h·ª£p ƒëi·ªÅu ki·ªán ng∆∞·ªùi d√πng)
- V·ªõi m·ªói tuple ‚Üí sinh ra `NUM_QUERIES_PER_TUPLE` c√¢u h·ªèi t·ª± nhi√™n
- Ch·∫°y **song song nhi·ªÅu thread** ƒë·ªÉ t·ªëi ∆∞u th·ªùi gian
- Tr·∫£ v·ªÅ danh s√°ch c√°c ƒë·ªëi t∆∞·ª£ng `QueryWithDimensions`, m·ªói item g·ªìm:

  - ID
  - C√¢u h·ªèi
  - Th√¥ng tin dimension t∆∞∆°ng ·ª©ng

## üìå Gi·∫£i th√≠ch chi ti·∫øt:

### H√†m nh·∫≠n v√†o:

```python
def generate_queries_parallel(dimension_tuples: List[DimensionTuple]) -> List[QueryWithDimensions]:
```

- `dimension_tuples`: danh s√°ch c√°c `DimensionTuple` b·∫°n ƒë√£ generate tr∆∞·ªõc ƒë√≥
- Tr·∫£ v·ªÅ: danh s√°ch `QueryWithDimensions` ‚Äì object ch·ª©a query v√† metadata li√™n quan

### 1. Kh·ªüi t·∫°o:

```python
all_queries = []
query_id = 1
```

- `all_queries`: n∆°i l∆∞u to√†n b·ªô k·∫øt qu·∫£ cu·ªëi c√πng
- `query_id`: d√πng ƒë·ªÉ t·∫°o ID d·∫°ng `SYN001`, `SYN002`,...

### 2. Kh·ªüi t·∫°o thread pool:

```python
with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
```

- T·∫°o m·ªôt thread pool v·ªõi s·ªë lu·ªìng t·ªëi ƒëa l√† `MAX_WORKERS` (gi√° tr·ªã khai b√°o ·ªü n∆°i kh√°c)

### 3. Submit task song song:

```python
future_to_tuple = {
    executor.submit(generate_queries_for_tuple, dim_tuple): i
    for i, dim_tuple in enumerate(dimension_tuples)
}
```

- M·ªói `generate_queries_for_tuple()` (t·ª©c g·ªçi GPT ƒë·ªÉ t·∫°o c√¢u h·ªèi t·ª´ 1 tuple) l√† m·ªôt task
- `future_to_tuple`: √°nh x·∫° t·ª´ng thread future v·ªÅ index ban ƒë·∫ßu trong list

### 4. Thu k·∫øt qu·∫£ v√† hi·ªÉn th·ªã ti·∫øn ƒë·ªô:

```python
with tqdm(total=len(dimension_tuples), desc="Generating Queries") as pbar:
    for future in as_completed(future_to_tuple):
```

- D√πng `tqdm` ƒë·ªÉ hi·ªÉn th·ªã progress bar
- `as_completed()` gi√∫p x·ª≠ l√Ω theo th·ª© t·ª± ho√†n th√†nh (b·∫•t k·ªÉ th·ª© t·ª± ban ƒë·∫ßu)

### 5. X·ª≠ l√Ω k·∫øt qu·∫£ t·ª´ng future:

```python
queries = future.result()
```

- N·∫øu th√†nh c√¥ng:

  - M·ªói c√¢u query s·∫Ω ƒë∆∞·ª£c ƒë√≥ng g√≥i v√†o `QueryWithDimensions` v·ªõi ID, c√¢u h·ªèi, v√† dimension
  - Append v√†o `all_queries`

```python
all_queries.append(QueryWithDimensions(
    id=f"SYN{query_id:03d}",
    query=query,
    dimension_tuple=dimension_tuples[tuple_idx]
))
query_id += 1
```

- N·∫øu l·ªói: in ra exception (kh√¥ng crash to√†n b·ªô)

```python
except Exception as e:
    print(f"Tuple {tuple_idx + 1} generated an exception: {e}")
```

### 6. Tr·∫£ k·∫øt qu·∫£:

```python
return all_queries
```

## üß± C√°c class ph·ª• thu·ªôc:

| Class                        | M·ª•c ƒë√≠ch                                             |
| ---------------------------- | ---------------------------------------------------- |
| `DimensionTuple`             | M·ªôt t·ªï h·ª£p ƒëi·ªÅu ki·ªán (diet, time, cuisine, v.v.)     |
| `QueryWithDimensions`        | Pydantic model ch·ª©a `id`, `query`, `dimension_tuple` |
| `generate_queries_for_tuple` | H√†m g·ªçi GPT sinh queries cho 1 tuple                 |
| `MAX_WORKERS`                | S·ªë l∆∞·ª£ng thread song song (th∆∞·ªùng 4‚Äì8)               |

## ‚úÖ T√≥m t·∫Øt:

| √ù ch√≠nh  | Chi ti·∫øt                                          |
| -------- | ------------------------------------------------- |
| M·ª•c ti√™u | T·∫°o nhi·ªÅu c√¢u h·ªèi cho chatbot test                |
| Input    | List c√°c t√¨nh hu·ªëng ng∆∞·ªùi d√πng (dimension tuples) |
| Output   | List c√°c query k√®m theo metadata                  |
| T·ªëi ∆∞u   | Ch·∫°y ƒëa lu·ªìng ƒë·ªÉ sinh nhanh h∆°n                   |
| Ti·ªán √≠ch | C√≥ `tqdm` ƒë·ªÉ theo d√µi ti·∫øn ƒë·ªô                     |

---

---

## VIII. H√†m save_queries_to_csv() d√πng ƒë·ªÉ l∆∞u to√†n b·ªô danh s√°ch query ƒë√£ sinh ra v√†o file CSV.

```python
def save_queries_to_csv(queries: List[QueryWithDimensions]):
    """Save generated queries to CSV using pandas."""
    if not queries:
        print("No queries to save.")
        return

    # Convert to DataFrame
    df = pd.DataFrame([
        {
            'id': q.id,
            'query': q.query,
            'dimension_tuple_json': q.dimension_tuple.model_dump_json(),
            'is_realistic_and_kept': q.is_realistic_and_kept,
            'notes_for_filtering': q.notes_for_filtering
        }
        for q in queries
    ])

    # Save to CSV
    df.to_csv(OUTPUT_CSV_PATH, index=False)
    print(f"Saved {len(queries)} queries to {OUTPUT_CSV_PATH}")

```

## ‚úÖ M·ª•c ƒë√≠ch:

L∆∞u k·∫øt qu·∫£ t·ª´ b∆∞·ªõc generate (m·ªôt danh s√°ch `QueryWithDimensions`) th√†nh m·ªôt file CSV d·ªÖ x·ª≠ l√Ω sau n√†y (l·ªçc, ƒë√°nh gi√°, fine-tune, ph√¢n t√≠ch...).

## üìå Gi·∫£i th√≠ch chi ti·∫øt t·ª´ng ph·∫ßn:

### Kh·ªüi ƒë·∫ßu:

```python
if not queries:
    print("No queries to save.")
    return
```

- N·∫øu list `queries` r·ªóng th√¨ d·ª´ng l·∫°i, kh√¥ng l√†m g√¨ ti·∫øp.

### Chuy·ªÉn list ‚Üí Pandas DataFrame:

```python
df = pd.DataFrame([
    {
        'id': q.id,
        'query': q.query,
        'dimension_tuple_json': q.dimension_tuple.model_dump_json(),
        'is_realistic_and_kept': q.is_realistic_and_kept,
        'notes_for_filtering': q.notes_for_filtering
    }
    for q in queries
])
```

- Duy·ªát qua t·ª´ng item `q` trong list `queries`, t·∫°o dict g·ªìm:

  - `id`: v√≠ d·ª• `SYN001`
  - `query`: c√¢u h·ªèi sinh ra
  - `dimension_tuple_json`: to√†n b·ªô th√¥ng tin v·ªÅ ng∆∞·ªùi d√πng (dimension) ‚Üí serialize th√†nh JSON string
  - `is_realistic_and_kept`: bool ƒë√°nh d·∫•u c√¢u n√†y c√≥ ƒë∆∞·ª£c gi·ªØ l·∫°i kh√¥ng (d√†nh cho b∆∞·ªõc l·ªçc th·ªß c√¥ng)
  - `notes_for_filtering`: ghi ch√∫ n·∫øu c√¢u b·ªã lo·∫°i b·ªè (v√≠ d·ª•: qu√° kh√≥ hi·ªÉu, l·ªói ch√≠nh t·∫£ qu√° n·∫∑ng, bot b·ªã ng√°o,...)

‚û°Ô∏è T·∫°o th√†nh m·ªôt b·∫£ng (DataFrame) ƒë·ªÉ xu·∫•t ra d·ªÖ d√†ng.

### Ghi file CSV:

```python
df.to_csv(OUTPUT_CSV_PATH, index=False)
print(f"Saved {len(queries)} queries to {OUTPUT_CSV_PATH}")
```

- Ghi file ra ƒë∆∞·ªùng d·∫´n `OUTPUT_CSV_PATH` (khai b√°o ·ªü ƒë·∫ßu file)
- `index=False`: kh√¥ng ghi c·ªôt ch·ªâ m·ª•c

## üß± Ph·ª• thu·ªôc:

| Bi·∫øn                  | √ù nghƒ©a                                               |
| --------------------- | ----------------------------------------------------- |
| `QueryWithDimensions` | Class ch·ª©a `query`, `id`, `dimension_tuple`, v.v.     |
| `OUTPUT_CSV_PATH`     | ƒê∆∞·ªùng d·∫´n file CSV ƒë·ªÉ ghi ra                          |
| `model_dump_json()`   | H√†m c·ªßa Pydantic model ƒë·ªÉ chuy·ªÉn object ‚Üí JSON string |
| `pd.DataFrame()`      | T·∫°o b·∫£ng t·ª´ list c√°c dict                             |

## ‚úÖ T√≥m l·∫°i:

| M·ª•c      | √ù nghƒ©a                                                        |
| -------- | -------------------------------------------------------------- |
| üéØ       | Ghi list query ƒë√£ sinh ra v√†o CSV                              |
| ‚úÖ Check | N·∫øu kh√¥ng c√≥ query th√¨ tho√°t                                   |
| üèóÔ∏è       | M·ªói d√≤ng CSV ch·ª©a: id, query, dimension, flag gi·ªØ/l·ªçc, ghi ch√∫ |
| üß∞ D√πng  | cho b∆∞·ªõc l·ªçc, ph√¢n t√≠ch, training,...                          |

---

---

## IX. H√†m main() l√† ƒëi·ªÉm b·∫Øt ƒë·∫ßu to√†n b·ªô pipeline sinh d·ªØ li·ªáu cho chatbot, g·ªìm 2 b∆∞·ªõc ch√≠nh:

```python
def main():
    """Main function to generate and save queries."""
    if "OPENAI_API_KEY" not in os.environ:
        print("Error: OPENAI_API_KEY environment variable not set.")
        return

    start_time = time.time()

    # Step 1: Generate dimension tuples
    print("Step 1: Generating dimension tuples...")
    dimension_tuples = generate_dimension_tuples()
    if not dimension_tuples:
        print("Failed to generate dimension tuples. Exiting.")
        return
    print(f"Generated {len(dimension_tuples)} dimension tuples.")

    # Step 2: Generate queries for each tuple
    print("\nStep 2: Generating natural language queries...")
    queries = generate_queries_parallel(dimension_tuples)

    if queries:
        save_queries_to_csv(queries)
        elapsed_time = time.time() - start_time
        print(f"\nQuery generation completed successfully in {elapsed_time:.2f} seconds.")
        print(f"Generated {len(queries)} queries from {len(dimension_tuples)} dimension tuples.")
    else:
        print("Failed to generate any queries.")
```

## ‚úÖ M·ª•c ti√™u t·ªïng th·ªÉ:

Sinh ra d·ªØ li·ªáu hu·∫•n luy·ªán (c√°c c√¢u h·ªèi ng∆∞·ªùi d√πng gi·∫£ l·∫≠p) theo c·∫•u tr√∫c v√† ti√™u ch√≠ ƒë·ªãnh s·∫µn ‚Üí ghi v√†o CSV.

## üìå Gi·∫£i th√≠ch t·ª´ng ph·∫ßn:

### üîê Check API key:

```python
if "OPENAI_API_KEY" not in os.environ:
    print("Error: OPENAI_API_KEY environment variable not set.")
    return
```

- N·∫øu ch∆∞a c·∫•u h√¨nh `OPENAI_API_KEY` trong `.env` ho·∫∑c m√¥i tr∆∞·ªùng ‚Üí tho√°t ngay.
- V√¨ code c·∫ßn g·ªçi API (`completion()` t·ª´ `litellm`), key l√† b·∫Øt bu·ªôc.

### üïí B·∫Øt ƒë·∫ßu t√≠nh th·ªùi gian:

```python
start_time = time.time()
```

### üß© B∆∞·ªõc 1: Sinh c√°c ‚Äúdimension tuples‚Äù

```python
print("Step 1: Generating dimension tuples...")
dimension_tuples = generate_dimension_tuples()
```

- G·ªçi h√†m `generate_dimension_tuples()` ‚Üí sinh ra N t·ªï h·ª£p ƒë·∫∑c ƒëi·ªÉm ng∆∞·ªùi d√πng (dietary, skill, cuisine, ...).
- M·ªói t·ªï h·ª£p l√† 1 profile user ƒë·ªÉ d√πng sinh query.

```python
if not dimension_tuples:
    print("Failed to generate dimension tuples. Exiting.")
    return
print(f"Generated {len(dimension_tuples)} dimension tuples.")
```

### üí¨ B∆∞·ªõc 2: Sinh c√¢u h·ªèi theo t·ª´ng profile

```python
print("\nStep 2: Generating natural language queries...")
queries = generate_queries_parallel(dimension_tuples)
```

- G·ªçi `generate_queries_parallel()` ƒë·ªÉ sinh ra danh s√°ch c√¢u h·ªèi t·ª± nhi√™n t∆∞∆°ng ·ª©ng v·ªõi t·ª´ng dimension tuple.
- M·ªói dimension tuple sinh ra `NUM_QUERIES_PER_TUPLE` c√¢u.

### üíæ L∆∞u CSV n·∫øu th√†nh c√¥ng:

```python
if queries:
    save_queries_to_csv(queries)
    elapsed_time = time.time() - start_time
    print(f"\nQuery generation completed successfully in {elapsed_time:.2f} seconds.")
    print(f"Generated {len(queries)} queries from {len(dimension_tuples)} dimension tuples.")
```

- G·ªçi `save_queries_to_csv()` ƒë·ªÉ ghi k·∫øt qu·∫£ ra file.
- In th·ªùi gian ch·∫°y v√† t·ªïng s·ªë query sinh ƒë∆∞·ª£c.

### ‚ùå N·∫øu kh√¥ng c√≥ query:

```python
else:
    print("Failed to generate any queries.")
```

## üîÅ D√≤ng ch·∫£y t·ªïng qu√°t:

```text
Check key ‚Üí Sinh profile user ‚Üí Sinh query t·ª´ profile ‚Üí Ghi file CSV
```

## üìå H√†m `main()` th∆∞·ªùng ƒë∆∞·ª£c g·ªçi ·ªü cu·ªëi file nh∆∞ sau:

```python
if __name__ == "__main__":
    main()
```

## ‚úÖ T√≥m g·ªçn 1 c√¢u:

> H√†m `main()` orchestrate to√†n b·ªô pipeline t·ª´ g·ªçi API, sinh d·ªØ li·ªáu ng∆∞·ªùi d√πng ‚Üí sinh c√¢u h·ªèi ‚Üí ghi file CSV ƒë·ªÉ l√†m dataset hu·∫•n luy·ªán/fine-tune cho chatbot.
