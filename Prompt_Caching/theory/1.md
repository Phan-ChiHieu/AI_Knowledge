## ğŸ“˜ I. Prompt Caching lÃ  gÃ¬? (Kiáº¿n thá»©c chuáº©n)

![Images Demo](./imgs/1.webp)

- Hiá»ƒu Ä‘Ãºng báº£n cháº¥t, Prompt Caching lÃ  má»™t ká»¹ thuáº­t tá»‘i Æ°u khi sá»­ dá»¥ng Large Language Models (LLMs) (nhÆ° GPT, Gemini, Claude...) Ä‘á»ƒ:

> **LÆ°u trá»¯ (cache)** cÃ¡c cÃ¢u há»i vÃ  cÃ¢u tráº£ lá»i Ä‘Ã£ tá»«ng gá»­i tá»›i model, nháº±m trÃ¡nh gá»i láº¡i API khÃ´ng cáº§n thiáº¿t, tá»« Ä‘Ã³ tiáº¿t kiá»‡m chi phÃ­, tÄƒng tá»‘c Ä‘á»™ pháº£n há»“i, vÃ  giáº£m táº£i há»‡ thá»‘ng.

![Images Demo](./imgs/2.webp)

### âœ… Äá»‹nh nghÄ©a chuáº©n:

> **Prompt Caching** lÃ  má»™t ká»¹ thuáº­t trong há»‡ thá»‘ng sá»­ dá»¥ng LLM (Large Language Model) Ä‘á»ƒ **lÆ°u láº¡i cÃ¡c truy váº¥n (prompt) vÃ  káº¿t quáº£ (response)**. Khi gáº·p láº¡i truy váº¥n giá»‘ng hoáº·c tÆ°Æ¡ng tá»±, há»‡ thá»‘ng **tráº£ káº¿t quáº£ Ä‘Ã£ lÆ°u**, khÃ´ng cáº§n gá»i láº¡i model â†’ giÃºp **giáº£m chi phÃ­, tÄƒng tá»‘c, giáº£m táº£i model**.

### Má»¥c tiÃªu:

- ğŸ’° Tiáº¿t kiá»‡m chi phÃ­ gá»i API LLM (GPT-4, Claude, Gemini,...)

- âš¡ TÄƒng tá»‘c pháº£n há»“i

- ğŸ§  TÃ¡i sá»­ dá»¥ng kiáº¿n thá»©c Ä‘Ã£ sinh ra

- ğŸ“‰ Giáº£m táº£i háº¡ táº§ng khi self-hosting (vá»›i GPU Ä‘áº¯t Ä‘á»)

#### ğŸ“Œ Yáº¿u tá»‘ cáº§n quan tÃ¢m: TTL (Time-to-Live): khÃ´ng cache mÃ£i mÃ£i â€” cáº§n xÃ³a Ä‘á»‹nh ká»³ Ä‘á»ƒ trÃ¡nh stale data.

## âš™ï¸ CÃ³ máº¥y loáº¡i Prompt Caching?

| Loáº¡i                    | CÃ¡ch hoáº¡t Ä‘á»™ng                                                                | Æ¯u Ä‘iá»ƒm                                 | Háº¡n cháº¿                                        |
| ----------------------- | ----------------------------------------------------------------------------- | --------------------------------------- | ---------------------------------------------- |
| **Exact Match Caching** | Hash cÃ¢u há»i (VD: báº±ng MD5/SHA256), so sÃ¡nh 100% giá»‘ng                        | Nhanh, Ä‘Æ¡n giáº£n                         | KhÃ´ng xá»­ lÃ½ Ä‘Æ°á»£c cÃ¢u há»i khÃ¡c cÃ¡ch diá»…n Ä‘áº¡t    |
| **Semantic Caching**    | Embedding cÃ¢u há»i (Vector hÃ³a) + cosine similarity Ä‘á»ƒ tÃ¬m cÃ¢u há»i _gáº§n nghÄ©a_ | Báº¯t Ä‘Æ°á»£c cÃ¡c cÃ¢u há»i diá»…n Ä‘áº¡t khÃ¡c nhau | Phá»©c táº¡p hÆ¡n, cáº§n model embedding vÃ  vector DB |

### 1. **Exact Prompt Cache (Bá»™ nhá»› truy váº¥n y há»‡t)**

![Images Demo](./imgs/3.webp)

- **CÆ¡ cháº¿**: bÄƒm cÃ¢u há»i thÃ nh mÃ£ (VD: MD5 hoáº·c SHA256), check xem mÃ£ Ä‘Ã£ cÃ³ trong cache chÆ°a.
- **CÃ´ng nghá»‡**: Redis, SQLite, MongoDB, file JSON (demo).
- **Æ¯u Ä‘iá»ƒm**: cá»±c nhanh, Ä‘Æ¡n giáº£n.
- **Háº¡n cháº¿**: khÃ´ng phÃ¡t hiá»‡n Ä‘Æ°á»£c cÃ¡c cÃ¢u há»i â€œgáº§n giá»‘ngâ€ (cÃ¹ng nghÄ©a, khÃ¡c chá»¯).

```python
import hashlib
def hash_prompt(prompt): return hashlib.md5(prompt.encode()).hexdigest()
```

### 2. **Semantic Prompt Cache (Ngá»¯ nghÄ©a)**

- **CÆ¡ cháº¿**:

  - Embedding prompt â†’ vector.
  - So sÃ¡nh cosine similarity vá»›i cÃ¡c prompt Ä‘Ã£ lÆ°u.
  - Náº¿u vÆ°á»£t ngÆ°á»¡ng (vÃ­ dá»¥ 0.90) thÃ¬ coi nhÆ° trÃ¹ng â†’ dÃ¹ng káº¿t quáº£ Ä‘Ã£ cache.

- **CÃ´ng nghá»‡**:

  - Vector DB: FAISS, Qdrant, Weaviate, Milvus
  - Embedding: `text-embedding-3-small`, `bge-m3`, `Instructor`

- **Æ¯u Ä‘iá»ƒm**: báº¯t Ä‘Æ°á»£c cÃ¡c cÃ¢u há»i viáº¿t khÃ¡c nhau nhÆ°ng cÃ¹ng Ã½ nghÄ©a.
- **Háº¡n cháº¿**: tá»‘n tÃ i nguyÃªn, cáº§n vector store.

```python
from sentence_transformers import SentenceTransformer
model = SentenceTransformer("sentence-transformers/all-MiniLM-L6-v2")
embedding = model.encode("Thá»§ Ä‘Ã´ Viá»‡t Nam lÃ  gÃ¬?")
```

### 3. **Hybrid Cache (Káº¿t há»£p Exact + Semantic)**

- **Chiáº¿n lÆ°á»£c thá»±c táº¿ phá»• biáº¿n nháº¥t**:

  - BÆ°á»›c 1: thá»­ exact cache (hash).
  - BÆ°á»›c 2: náº¿u khÃ´ng cÃ³ â†’ dÃ¹ng semantic cache.
  - BÆ°á»›c 3: náº¿u váº«n khÃ´ng cÃ³ â†’ gá»i API model â†’ lÆ°u cache.

- **TTL** (Time to Live): má»—i prompt cÃ³ thá»ƒ cÃ³ háº¡n dÃ¹ng 1h, 24h, 7 ngÃ y...

## ğŸ“¦ VI. Má»™t sá»‘ tips thá»±c táº¿

| Tip                                                             | MÃ´ táº£                                  |
| --------------------------------------------------------------- | -------------------------------------- |
| âœ… DÃ¹ng threshold \~0.88â€“0.95 cho cosine similarity             | TÃ¹y vÃ o yÃªu cáº§u "trÃ¹ng nghÄ©a" kháº¯t khe |
| â±ï¸ TTL nÃªn gáº¯n theo loáº¡i prompt                                 | VD: tin tá»©c 2h, policy 7 ngÃ y          |
| ğŸ§© Má»—i embedding model sáº½ áº£nh hÆ°á»Ÿng Ä‘á»™ chÃ­nh xÃ¡c semantic match | NÃªn benchmark                          |
| âš ï¸ KhÃ´ng cache cÃ¢u há»i cÃ¡ nhÃ¢n hÃ³a (VD: "tÃ´i lÃ  ai?")           | Dá»… tráº£ sai káº¿t quáº£                     |
| ğŸ“ˆ Theo dÃµi tá»‰ lá»‡ hit/miss cá»§a cache                            | Äá»ƒ Ä‘Ã¡nh giÃ¡ hiá»‡u quáº£                   |

## ğŸ“š VII. TÃ i liá»‡u khuyáº¿n nghá»‹

- [GPTCache â€“ GitHub](https://github.com/zilliztech/GPTCache)
- [OpenAI - Prompt Caching Guide](https://platform.openai.com/docs/guides/prompt-caching)
- [Qdrant â€“ Vector Similarity Search](https://qdrant.tech/)
- [LangChain Memory](https://docs.langchain.com/docs/components/memory)
